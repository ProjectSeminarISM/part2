{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "#class torchvision.transforms.RandomResizedCrop(size, scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2)\n",
    "#transforms.RandomResizedCrop(224) --> A crop of random size (default: of 0.08 to 1.0) of the original size and a \n",
    "#random aspect ratio (default: of 3/4 to 4/3) of the original aspect ratio is made. \n",
    "#This crop is finally resized to given size (224 in this case). \n",
    "#transforms.CenterCrop(224)--> Crops the image at the center. 224 is the Desired output size of the crop.\n",
    "#class torchvision.transforms.Normalize(mean, std)\n",
    "#Normalize a tensor image with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, \n",
    "#this transform will normalize each channel of the input torch.Tensor i.e. \n",
    "#input[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "#Parameters:     mean (sequence) – Sequence of means for each channel.\n",
    "#                std (sequence) – Sequence of standard deviations for each channel.\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(440),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        transforms.CenterCrop(440),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Names: ['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC']\n",
      "There are 76 batches in the training set\n",
      "There are 26 batches in the test set\n",
      "There are 7504 training images\n",
      "There are 2511 testing images\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'lesion_data_multiclass'\n",
    "#Create a dictionary that contains the information of the images in both the training and validation set\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),data_transforms[x]) for x in ['train', 'val']}\n",
    "#Create a dictionary that contians the data loader\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=100,\n",
    "                                              shuffle=True) for x in ['train', 'val']}\n",
    "\n",
    "#Create a dictionary that contains the size of each dataset (training and validation)\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "#Get the class names\n",
    "class_names = image_datasets['train'].classes\n",
    "#Print out the results \n",
    "print(\"Class Names: {}\".format(class_names))\n",
    "print(\"There are {} batches in the training set\".format(len(dataloaders['train'])))\n",
    "print(\"There are {} batches in the test set\".format(len(dataloaders['val'])))\n",
    "print(\"There are {} training images\".format(dataset_sizes['train']))\n",
    "print(\"There are {} testing images\".format(dataset_sizes['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model class\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #Same Padding = [(filter size - 1) / 2] (Same Padding--> input size = output size)\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
    "        #The output size of each of the 8 feature maps is \n",
    "        #[(input_size - filter_size + 2(padding) / stride) +1] --> [(450-3+2(1)/1)+1] = 440 (padding type is same)\n",
    "        #Batch normalization\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        #RELU\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is now 440/2 = 220\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        #Output size of each of the 32 feature maps remains 220\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is 220/2 = 110\n",
    "        #Flatten the feature maps. You have 32 feature maps, each of them is of size 110x110 --> 32*110*110 = 387200\n",
    "        self.fc1 = nn.Linear(in_features=387200, out_features=600)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=7)\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #Now we have to flatten the output. This is where we apply the feed forward neural network as learned before! \n",
    "        #It will take the shape (batch_size, 387200) = (100, 387200)\n",
    "        out = out.view(-1,387200)\n",
    "        #Then we forward through our fully connected layer \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()    \n",
    "loss_fn = nn.CrossEntropyLoss()        \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For one iteration, this is what happens:\n",
      "Input Shape: torch.Size([100, 3, 440, 440])\n",
      "Labels Shape: torch.Size([100])\n",
      "Outputs Shape torch.Size([100, 7])\n",
      "Predicted Shape torch.Size([100])\n",
      "Predicted Tensor:\n",
      "tensor([4, 1, 2, 4, 4, 1, 1, 1, 1, 4, 2, 4, 1, 1, 3, 6, 0, 2, 1, 1, 1, 1, 4, 1,\n",
      "        1, 3, 4, 1, 3, 2, 0, 1, 4, 2, 3, 1, 1, 4, 1, 4, 3, 4, 4, 6, 4, 1, 1, 1,\n",
      "        4, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 3, 4, 4, 1, 5, 2, 4, 1, 1, 1, 4, 1, 5,\n",
      "        4, 1, 6, 2, 1, 3, 1, 1, 1, 2, 2, 4, 1, 0, 1, 0, 1, 0, 4, 4, 4, 6, 1, 1,\n",
      "        2, 1, 6, 4])\n",
      "Correct Predictions:  tensor(9)\n",
      "Correct Predictions: tensor(9)\n"
     ]
    }
   ],
   "source": [
    "#Understand what's happening\n",
    "iteration = 0\n",
    "correct_nodata = 0\n",
    "correct_data = 0\n",
    "for inputs,labels in dataloaders['train']:\n",
    "    if iteration==1:\n",
    "        break\n",
    "    inputs = Variable(inputs)\n",
    "    labels = Variable(labels)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "    print(\"For one iteration, this is what happens:\")\n",
    "    print(\"Input Shape:\",inputs.shape)\n",
    "    print(\"Labels Shape:\",labels.shape)\n",
    "    output = model(inputs)\n",
    "    print(\"Outputs Shape\",output.shape)\n",
    "    _, predicted_nodata = torch.max(output, 1)\n",
    "    print(\"Predicted Shape\",predicted_nodata.shape)\n",
    "    print(\"Predicted Tensor:\")\n",
    "    print(predicted_nodata)\n",
    "    correct_nodata += (predicted_nodata == labels).sum()\n",
    "    print(\"Correct Predictions: \",correct_nodata)\n",
    "    _, predicted_data = torch.max(output.data, 1)\n",
    "    correct_data += (predicted_data == labels.data).sum()\n",
    "    print(\"Correct Predictions:\",correct_data)\n",
    "    \n",
    "\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the CNN\n",
    "num_epochs = 25\n",
    "\n",
    "#Define the lists to store the results of loss and accuracy\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#Training\n",
    "for epoch in range(num_epochs): \n",
    "    #Reset these below variables to 0 at the begining of every epoch\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    iter_loss = 0.0\n",
    "    \n",
    "    model.train()                   # Put the network into training mode\n",
    "    \n",
    "    for inputs,labels in dataloaders['train']:\n",
    "        \n",
    "        # Convert torch tensor to Variable\n",
    "        inputs = Variable(inputs)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # If we have GPU, shift the data to GPU\n",
    "        CUDA = torch.cuda.is_available()\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()            # Clear off the gradient in (w = w - gradient)\n",
    "        outputs = model(inputs)         \n",
    "        loss = loss_fn(outputs, labels)  \n",
    "        iter_loss += loss.data[0]       # Accumulate the loss\n",
    "        loss.backward()                 # Backpropagation \n",
    "        optimizer.step()                # Update the weights\n",
    "        \n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        iterations += 1\n",
    "    \n",
    "    # Record the training loss\n",
    "    train_loss.append(iter_loss/iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(train_dataset)))\n",
    "   \n",
    "    #Testing\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()                    # Put the network into evaluation mode\n",
    "    \n",
    "    for inputs, labels in dataloaders['val']:\n",
    "        \n",
    "        # Convert torch tensor to Variable\n",
    "        inputs = Variable(inputs)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        CUDA = torch.cuda.is_available()\n",
    "        if CUDA:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(inputs)     \n",
    "        loss = loss_fn(outputs, labels) # Calculate the loss\n",
    "        loss += loss.data[0]\n",
    "        # Record the correct predictions for training data\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    # Record the Testing loss\n",
    "    test_loss.append(loss/iterations)\n",
    "    # Record the Testing accuracy\n",
    "    test_accuracy.append((100 * correct / len(test_dataset)))\n",
    "    \n",
    "    print ('Epoch {}/{}, Training Loss: {:.3f}, Training Accuracy: {:.3f}, Testing Loss: {:.3f}, Testing Acc: {:.3f}'\n",
    "           .format(epoch+1, num_epochs, train_loss[-1], train_accuracy[-1], \n",
    "             test_loss[-1], test_accuracy[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "f = plt.figure(figsize=(10, 10))\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(test_accuracy, label='Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = test_dataset[30][0].resize_((1, 1, 28, 28))   #(batch_size,channels,height,width)\n",
    "img = Variable(img)\n",
    "label = test_dataset[30][1]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    img = img.cuda()\n",
    "    \n",
    "output = model(img)\n",
    "print(output)\n",
    "print(output.data)\n",
    "_, predicted = torch.max(output,1)\n",
    "print(\"Prediction is: \", predicted.item())\n",
    "print(\"Actual is is : \", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
